{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from multiprocessing import Pool,cpu_count\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class probabilityFunction:\n",
    "\n",
    "    def __init__(self,opt_space,iteration,sample_id,objective_,optimizer,search_based,hybrid,RF_depth,RF_estimator,no_selections):\n",
    "        \n",
    "        self.space = opt_space\n",
    "\n",
    "\n",
    "        self.based = search_based\n",
    "\n",
    "        self.iteration = iteration\n",
    "        self.evaluated = self.space[self.space['objective'].notnull()].index.values\n",
    "        self.sample_id = sample_id\n",
    "        self.objective = objective_\n",
    "\n",
    "        self.depth = RF_depth\n",
    "        self.estimator = RF_estimator\n",
    "        self.no_selections = no_selections\n",
    "        \n",
    "        self.pd_header = list(self.space)\n",
    "        self.no_variables = len(self.pd_header) - len(sys_information)\n",
    "        \n",
    "\n",
    "        self.mesh_points, self.tab_columns = self.space.shape\n",
    "\n",
    "\n",
    "    # ================================\n",
    "    # ================================\n",
    "    def hybridWAM(self):\n",
    "        global prob_model_r2\n",
    "        global prob_model\n",
    "\n",
    "        learning_limit = 0.99\n",
    "\n",
    "        probability = np.zeros(self.mesh_points)\n",
    "\n",
    "\n",
    "        # Check learning status and use random selection\n",
    "        if((prob_model_r2 <= learning_limit) or (len(self.evaluated) < 0.01*self.mesh_points)):\n",
    "            \n",
    "            inputs_ = self.space[self.pd_header[:self.no_variables]].loc[self.evaluated].as_matrix().reshape((-1,self.no_variables))\n",
    "            outputs_ = self.space['objective'].loc[self.evaluated].as_matrix().flatten()\n",
    "\n",
    "            prob_model = RandomForestRegressor(max_depth=len(self.evaluated), n_estimators=self.estimator)  #, n_jobs=-1)\n",
    "            prob_model.fit(inputs_, outputs_)\n",
    "            probability_ = prob_model.predict(inputs_)\n",
    "\n",
    "\n",
    "            prob_model_r2 = r2_score(outputs_,probability_)\n",
    "\n",
    "            learning_curve.append([self.iteration,len(self.evaluated),prob_model_r2])\n",
    "\n",
    "\n",
    "        # use RF-WAM function\n",
    "        if(prob_model_r2 > learning_limit):\n",
    "            \n",
    "            #probability = self.randomforest()\n",
    "            inputs_ = self.space[self.pd_header[:self.no_variables]].as_matrix().reshape((-1,self.no_variables))\n",
    "            probability_ = prob_model.predict(inputs_)\n",
    "\n",
    "            prob_ = probability_ * self.space[\"weighting\"].as_matrix()\n",
    "            \n",
    "            prob_matrix = np.stack((self.space.index.values,prob_), axis=-1)\n",
    "            prob_matrix = np.delete(prob_matrix,np.where(prob_matrix[:,1] == 0)[0],axis=0)\n",
    "            \n",
    "\n",
    "            selected_index = prob_matrix[prob_matrix[:, 1].argsort()][::-1][:self.no_selections,0].astype(int)\n",
    "\n",
    "\n",
    "            probability[selected_index] = 1.\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        return probability\n",
    "\n",
    "    # ================================\n",
    "    # ================================\n",
    "\n",
    "\n",
    "\n",
    "    def randomforest(self):\n",
    "\n",
    "    # train randomforest model for probability function\n",
    "\n",
    "        # the for loop cost 420.534-356.826 more seconds\n",
    "        '''\n",
    "        inputs_ = self.space[self.pd_header[0]].loc[self.evaluated].as_matrix().reshape((-1,1))\n",
    "\n",
    "        for header_ in self.pd_header[1:-3]:\n",
    "            inputs_ = np.hstack((inputs_,self.space[header_].loc[self.evaluated].as_matrix().reshape((-1,1))))\n",
    "        '''\n",
    "\n",
    "        inputs_ = self.space[self.pd_header[:self.no_variables]].loc[self.evaluated].as_matrix().reshape((-1,self.no_variables))\n",
    "\n",
    "        outputs_ = self.space['objective'].loc[self.evaluated].as_matrix().flatten()\n",
    "\n",
    "        #prob_model = RandomForestRegressor(max_depth=self.depth, n_estimators=self.estimator)\n",
    "        prob_model = RandomForestRegressor(max_depth=len(self.evaluated), n_estimators=self.estimator)  #, n_jobs=-1)\n",
    "        prob_model.fit(inputs_, outputs_)\n",
    "\n",
    "\n",
    "        '''\n",
    "        # to estimate the uncertainty (confidence interval)\n",
    "        calculated_table = []\n",
    "        for pred in prob_model.estimator:\n",
    "            calculated_table.append(pred.predict(inputs_))\n",
    "        '''\n",
    "\n",
    "\n",
    "        # use randomforest model to estimate the probability function\n",
    "        '''\n",
    "        inputs_ = self.space[self.pd_header[0]].as_matrix().reshape((-1,1))\n",
    "\n",
    "        for header_ in self.pd_header[1:-3]:\n",
    "            inputs_ = np.hstack((inputs_,self.space[header_].as_matrix().reshape((-1,1))))\n",
    "        '''\n",
    "\n",
    "        inputs_ = self.space[self.pd_header[:self.no_variables]].as_matrix().reshape((-1,self.no_variables))\n",
    "\n",
    "\n",
    "        # =====================================================================\n",
    "        # the selsction mechanisms are very different\n",
    "        # 'monte-carlo' uses probability for selection\n",
    "        # 'whack-a-mole' sorts probability matrix and uses the highest points\n",
    "        # =====================================================================\n",
    "        if( self.based == 'monte-carlo'):\n",
    "            probability = prob_model.predict(inputs_)\n",
    "\n",
    "        # while the objective values are negative\n",
    "        # the probabilities are negative\n",
    "        # the curve is therefore shifted above the zero\n",
    "        # this is different from probability matrix\n",
    "            probability += np.amin(probability)\n",
    "\n",
    "        # if objective is negative, the probability will be negative\n",
    "        # this maximization function enforces 0 on probability\n",
    "            probability[probability<0] = 0.\n",
    "\n",
    "\n",
    "\n",
    "        elif(self.based =='whack-a-mole'):\n",
    "\n",
    "            probability = np.zeros(self.mesh_points)\n",
    "            \n",
    "            probability_ = prob_model.predict(inputs_)\n",
    "            prob_matrix = probability_ * self.space[\"weighting\"].as_matrix()\n",
    "\n",
    "\n",
    "            # while the objective values are negative\n",
    "            # the probability is negative\n",
    "            # in probability matrix, the calculated points possess the highest objective value =0\n",
    "            # which are removed from probability matrix\n",
    "\n",
    "            prob_ = probability_ * self.space[\"weighting\"].as_matrix()\n",
    "            \n",
    "            prob_matrix = np.stack((self.space.index.values,prob_), axis=-1)\n",
    "            prob_matrix = np.delete(prob_matrix,np.where(prob_matrix[:,1] == 0)[0],axis=0)\n",
    "            \n",
    "\n",
    "            selected_index = prob_matrix[prob_matrix[:, 1].argsort()][::-1][:self.no_selections,0].astype(int)\n",
    "\n",
    "            probability[selected_index] = 1.\n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            sys.exit(\"illeagle setting parameter: RF_search_based\")\n",
    "\n",
    "\n",
    "        return probability\n",
    "\n",
    "\n",
    "\n",
    "    def geneticalgorithm(self):\n",
    "\n",
    "        global GA_search_top\n",
    "        global GA_search_path\n",
    "\n",
    "\n",
    "        if(len(self.evaluated)>=self.mesh_points):\n",
    "            return np.full(self.mesh_points,0.)\n",
    "\n",
    "        elif(len(self.evaluated)>=self.mesh_points-self.no_selections):\n",
    "            return np.full(self.mesh_points,1.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # calculate required bits of a string for each variable\n",
    "        no_bits = np.zeros(self.no_variables+1,dtype=int)\n",
    "        binary_max = []\n",
    "\n",
    "        for ivar in range(self.no_variables):\n",
    "\n",
    "            bin_ = bin(no_gridpoints[ivar])[2:]\n",
    "            no_bits[ivar+1] = len(bin_)\n",
    "\n",
    "            binary_max.append(2**no_bits[ivar+1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if(self.based == 'family'):\n",
    "\n",
    "            no_objective_ = GA_no_parents\n",
    "            if(len(self.objective) < GA_no_parents):\n",
    "                no_objective_ = len(self.objective)\n",
    "\n",
    "\n",
    "            # obtain the maximum objective from current iteration\n",
    "            objective = sorted(self.objective, reverse=True)[:no_objective_]\n",
    "\n",
    "\n",
    "            # obtain the id from table\n",
    "            # GA-family is path dependent, \n",
    "            # so the selected samples will be passed to the next generation\n",
    "            #\n",
    "            id_ = []\n",
    "            for iobjective in range(no_objective_):\n",
    "                try:\n",
    "                    id_.extend([self.sample_id[self.objective.index(objective[iobjective])]])\n",
    "\n",
    "                except:\n",
    "\n",
    "                    print(iobjective,objective,self.objective,self.sample_id)\n",
    "                    print(len(self.evaluated),self.mesh_points)\n",
    "\n",
    "\n",
    "                    sys.exit(\"error from GA family method\")\n",
    "\n",
    "\n",
    "\n",
    "            # obtain the maximum objective from previous iteration\n",
    "            if GA_search_path:\n",
    "                objective.extend(GA_search_top)\n",
    "                id_.extend(GA_search_path[-1][1:])\n",
    "\n",
    "\n",
    "\n",
    "            objective_top = sorted(objective, reverse=True)[:GA_no_parents]            \n",
    "            GA_search_top = objective_top\n",
    "\n",
    "\n",
    "\n",
    "            GA_search_path.append([self.iteration])\n",
    "            for iobjective in range(GA_no_parents):\n",
    "                GA_search_path[-1].extend([id_[objective.index(objective_top[iobjective])]])\n",
    "\n",
    "\n",
    "\n",
    "        elif(self.based == 'global'):\n",
    "\n",
    "            objective = np.sort(self.space['objective'].fillna(value=0.))[::-1]\n",
    "\n",
    "\n",
    "            GA_search_path.append([self.iteration])\n",
    "\n",
    "            for iobjective in range(GA_no_parents):\n",
    "\n",
    "                index_ = self.space[self.space['objective'] == objective[iobjective] ].index.values\n",
    "                GA_search_path[-1].extend(index_)\n",
    "\n",
    "        else:\n",
    "            sys.exit(\"illeagle setting parameters: GA_search_based\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        bitcount = np.cumsum(no_bits)\n",
    "        # get positions of parents in axes in binary strings\n",
    "        ga_parents = []\n",
    "        for imax in range(GA_no_parents):\n",
    "\n",
    "            selections = [GA_search_path[-1][imax+1]]\n",
    "\n",
    "\n",
    "\n",
    "            variable_ = self.space[self.pd_header[0]].loc[selections].values[0]\n",
    "            bin_variable_ = bin(np.where(var_space[0] == variable_)[0][0])[2:].zfill(no_bits[1])\n",
    "            ga_parents_ = bin_variable_\n",
    "\n",
    "\n",
    "            for ivar in range(1,self.no_variables):\n",
    "\n",
    "                header_ = self.pd_header[ivar]\n",
    "\n",
    "                variable_ = self.space[header_].loc[selections].values[0]\n",
    "\n",
    "                # convert the best to binary string\n",
    "                bin_variable_ = bin(np.where(var_space[ivar] == variable_)[0][0])[2:].zfill(no_bits[ivar+1])\n",
    "\n",
    "                ga_parents_ += bin_variable_\n",
    "                #ga_parents_ = np.hstack((ga_parents_,bin_variable_))\n",
    "\n",
    "\n",
    "            ga_parents.append(ga_parents_)\n",
    "\n",
    "\n",
    "        total_bits = len(ga_parents[0])\n",
    "\n",
    "\n",
    "        similarity = 0.\n",
    "        for ibits in range(total_bits):\n",
    "            if ga_parents[0][ibits] == ga_parents[1][ibits]:\n",
    "                similarity += 1.\n",
    "\n",
    "\n",
    "    # ==== convergence/similarity test\n",
    "        if (similarity/total_bits >= GA_convergence) or (similarity >= total_bits-1):\n",
    "            probability = np.full(self.mesh_points,1.)\n",
    "\n",
    "            GA_search_top = [0]*GA_no_parents\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            no_children = self.no_selections - GA_no_parents\n",
    "\n",
    "\n",
    "            opt_index = []\n",
    "            opt_attempts = 0\n",
    "            while (not opt_index):\n",
    "\n",
    "                for ichild in range(no_children):\n",
    "\n",
    "                    # selection for cross-over\n",
    "                    randomselection = sorted(random.sample(range(0, total_bits), 2))\n",
    "\n",
    "\n",
    "                    # cross-over\n",
    "                    children_ = (ga_parents[0][0:randomselection[0]] \n",
    "                                 + ga_parents[1][randomselection[0]:randomselection[1]] \n",
    "                                 + ga_parents[0][randomselection[1]:])\n",
    "\n",
    "\n",
    "                    # mutation\n",
    "                    randomselection = random.sample(range(0, len(ga_parents[0])), int(mutation_rate*total_bits))\n",
    "\n",
    "\n",
    "\n",
    "                    children_ = (children_[:randomselection[0]] \n",
    "                                 + str(abs(int(children_[randomselection[0]]) - 1)) \n",
    "                                 + children_[randomselection[0]+1:])\n",
    "\n",
    "\n",
    "                    # convert back to search space\n",
    "                    children = []\n",
    "                    for ivar in range(self.no_variables):\n",
    "\n",
    "                        binary_ = children_[bitcount[ivar]:bitcount[ivar+1]]\n",
    "\n",
    "                        position_ = int(float(int(binary_, 2))/binary_max[ivar] * no_gridpoints[ivar])\n",
    "\n",
    "\n",
    "                        value_ = var_space[ivar][position_]\n",
    "\n",
    "\n",
    "                        children.append(self.space[self.space[self.pd_header[ivar]] == value_].index.values)\n",
    "\n",
    "\n",
    "                    opt_index_ = children[0]\n",
    "                    for ivar in range(1,self.no_variables):\n",
    "                        opt_index_ = list(set(opt_index_).intersection(children[ivar]))\n",
    "\n",
    "                    opt_index.append(opt_index_[0])\n",
    "\n",
    "\n",
    "\n",
    "                opt_index = sorted(list(set(opt_index)))\n",
    "\n",
    "\n",
    "                check_probability = sorted(list(set(self.evaluated).intersection(opt_index)))\n",
    "\n",
    "                # ==== convergence test\n",
    "                # if the selected inputs are calculated, it turns into random selection\n",
    "                #\n",
    "                if check_probability == opt_index:\n",
    "\n",
    "                    #print(\"1\",self.iteration)\n",
    "                    opt_attempts += 1\n",
    "\n",
    "                    if opt_attempts == 10:\n",
    "                        probability = np.full(self.mesh_points,1.)\n",
    "\n",
    "                        GA_search_top = [0]*GA_no_parents\n",
    "\n",
    "                    else:\n",
    "                        opt_index = []\n",
    "\n",
    "\n",
    "\n",
    "                # the probability matrix (prob_matrix) must larger than GA_no_parents\n",
    "                # eq: 0,x,1 to get at least 2 calculations as parent samples\n",
    "                #\n",
    "\n",
    "                elif( (self.mesh_points - len(self.evaluated) > GA_no_parents) \n",
    "                     & (len(opt_index) - len(check_probability) < (GA_no_parents+1)) ):\n",
    "\n",
    "                    #print(\"2\",self.iteration)\n",
    "                    opt_attempts += 1\n",
    "\n",
    "                    if opt_attempts == 10:\n",
    "                        probability = np.full(self.mesh_points,1.)\n",
    "\n",
    "                        GA_search_top = [0]*GA_no_parents\n",
    "\n",
    "                    else:\n",
    "                        opt_index = []\n",
    "\n",
    "\n",
    "                elif (self.mesh_points - len(self.evaluated) > GA_no_parents) & (len(opt_index) == 1):\n",
    "\n",
    "                    #print(\"3\",self.iteration)\n",
    "                    opt_attempts += 1\n",
    "\n",
    "                    if opt_attempts == 10:\n",
    "                        probability = np.full(self.mesh_points,1.)\n",
    "\n",
    "                        GA_search_top = [0]*GA_no_parents\n",
    "\n",
    "                    else:\n",
    "                        opt_index = []              \n",
    "\n",
    "\n",
    "                else:\n",
    "                    probability = np.zeros(self.mesh_points)\n",
    "                    probability[opt_index] = 1.\n",
    "\n",
    "\n",
    "                    #prob_matrix = probability * self.space[\"weighting\"].as_matrix()\n",
    "\n",
    "\n",
    "\n",
    "        # while GA is converged, the probability function will be generated using RF-mc\n",
    "        if((hybrid == 1) & (np.round(np.mean(probability),6) == 1.)):\n",
    "            self.based = 'monte-carlo'\n",
    "\n",
    "            probability = self.randomforest()\n",
    "\n",
    "\n",
    "        # hybrid_3 is the combination of GA-family + 'RF-WAM'\n",
    "        if(hybrid == 3):\n",
    "            probability_ = self.hybridWAM()\n",
    "\n",
    "            if(np.count_nonzero(probability_) > 0):\n",
    "                probability = probability_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return probability\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def random(self):\n",
    "        probability = np.full(self.mesh_points,1.)\n",
    "\n",
    "\n",
    "        if(hybrid == 2):\n",
    "            probability_ = self.hybridWAM()\n",
    "\n",
    "            if(np.count_nonzero(probability_) > 0):\n",
    "                probability = probability_\n",
    "\n",
    "\n",
    "\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimization(evaluate,probFunctionName,noIteration,opt_space,RF_depth,RF_estimator,no_selections,saveSpace):\n",
    "\n",
    "    pd_header = list(opt_space)\n",
    "    no_variables = len(pd_header) - len(sys_information)\n",
    "    mesh_points, tab_columns = opt_space.shape  \n",
    "    \n",
    "    \n",
    "    prob_matrix = np.zeros(mesh_points)\n",
    "\n",
    "\n",
    "    #ML_matrix = [np.zeros(mesh_points)]\n",
    "    for iteration in range(noIteration):\n",
    "\n",
    "        evaluated = opt_space[opt_space['objective'].notnull()].index.values\n",
    "        \n",
    "        #print(iteration,len(evaluated),prob_model_r2)\n",
    "        #print(iteration,len(evaluated))\n",
    "        probsum = opt_space['objective'].sum()\n",
    "        #print(\"----\",len(evaluated), mesh_points)\n",
    "\n",
    "\n",
    "    # ====== select sample by the probability function\n",
    "        # probsum == 0 is the condition for constrain search\n",
    "        if((len(evaluated) >= mesh_points) or (probsum == 0) ):\n",
    "            #print(\"the space is fully evaluated: %d points\" %len(evaluated))\n",
    "            return opt_space\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            # first iteration of search\n",
    "            # the probability column is nan\n",
    "            if(len(evaluated)==0):\n",
    "                sampling = np.linspace(0.,1.-0.5/mesh_points,no_selections,endpoint=True)\n",
    "\n",
    "                sample_id = []\n",
    "                for isam in range(len(sampling)):\n",
    "                    sample_id.append(np.where(opt_space['probability']>sampling[isam])[0][0])\n",
    "\n",
    "\n",
    "                sample_id = np.unique(np.array(sample_id))\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                prob_ = np.unique(opt_space['probability'])\n",
    "\n",
    "\n",
    "                # for last iteration:\n",
    "                # all the remaining points are selected\n",
    "                if(len(evaluated) >= mesh_points-no_selections):\n",
    "           \n",
    "                    sample_id = opt_space[opt_space['objective'].isnull()].index.values\n",
    "\n",
    "\n",
    "                # the optimizers assign the probability to each grid point \n",
    "                # and the algorithm choose samples according to the probability\n",
    "                # for assigned sampling, random selection will cause lower calculation rate\n",
    "                elif(len(prob_) <= no_selections):\n",
    "\n",
    "                    sample_id = []\n",
    "                    for isam in range(1,len(prob_)):\n",
    "                        sample_id.append(np.where(opt_space['probability']==prob_[isam])[0][0])\n",
    "\n",
    "\n",
    "                else:\n",
    "            \n",
    "                    sampling = np.random.rand(1,no_selections)[0]\n",
    "\n",
    "                    sample_id = []\n",
    "                    for isam in range(len(sampling)):\n",
    "                        sample_id.append(np.where(opt_space['probability']>sampling[isam])[0][0])\n",
    "\n",
    "\n",
    "                    sample_id = np.unique(np.array(sample_id))\n",
    "\n",
    "\n",
    "        test_sample = np.around(opt_space[pd_header[:no_variables]].loc[sample_id].values, decimals=10)\n",
    "\n",
    "\n",
    "        \n",
    "        # ====== sample evaluation\n",
    "        objective_ = []\n",
    "        for isam in range(len(test_sample)):\n",
    "            objective_.append(evaluate(test_sample[isam]))\n",
    "\n",
    "\n",
    "            #print(\"OPT test sample: \",test_sample[isam])\n",
    "            #print(objective_[-1])\n",
    "\n",
    "\n",
    "            #opt_space['objective'].set_value(sample_id[isam], objective_[-1])\n",
    "            #opt_space['weighting'].set_value(sample_id[isam], 0.)\n",
    "            opt_space['objective'].iat[sample_id[isam]] = objective_[-1]\n",
    "            opt_space['weighting'].iat[sample_id[isam]] = 0.\n",
    "            opt_space['iteration'].iat[sample_id[isam]] = iteration\n",
    "\n",
    "        # ====== sample evaluation\n",
    "        \n",
    "        ''' # -- Parallel processing\n",
    "        processes = cpu_count()\n",
    "        if(processes == 0):\n",
    "          processes = 1\n",
    "\n",
    "        tasks = len(test_sample)//processes\n",
    "\n",
    "        with Pool(processes) as p:\n",
    "            objective_ = p.map(evaluate, test_sample, chunksize=tasks)\n",
    "        \n",
    "        \n",
    "        opt_space.loc[sample_id,['objective']] = objective_\n",
    "        opt_space.loc[sample_id,['weighting']] = 0.\n",
    "\t'''\n",
    "\n",
    "\n",
    "        prob = probabilityFunction(opt_space,iteration,sample_id,objective_,optimizer,search_based,hybrid,RF_depth,RF_estimator,no_selections)\n",
    "        functionName = getattr(prob,probFunctionName)\n",
    "        ML_matrix = functionName()\n",
    "\n",
    "\n",
    "\n",
    "        prob_matrix = ML_matrix * opt_space[\"weighting\"].as_matrix()\n",
    "\n",
    "\n",
    "        cum_prob_matrix = np.cumsum(prob_matrix)\n",
    "        max_prob = cum_prob_matrix[-1]\n",
    "\n",
    "\n",
    "        if max_prob == 0:\n",
    "            opt_space['probability'] = prob_matrix\n",
    "        else:\n",
    "            opt_space['probability'] = cum_prob_matrix/max_prob\n",
    "\n",
    "\n",
    "        if(saveSpace == 'save'):\n",
    "            opt_space.to_csv('opt_space.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    return opt_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(readfile,searchMesh,evaluate,optimization_method,no_selections,noIteration,saveSpace):\n",
    "#==========================================\n",
    "\n",
    "    no_variables = len(searchMesh)\n",
    "\n",
    "\n",
    "    global learning_curve\n",
    "    learning_curve = []\n",
    "\n",
    "# ===============================================================================\n",
    "# Create Mesh\n",
    "# ===============================================================================\n",
    "    # ======= inputs to the algorithm\n",
    "    #\n",
    "    # initiate pandas dataframe\n",
    "    #\n",
    "    pd_header = []\n",
    "    for ivar in range(no_variables):\n",
    "        pd_header.extend(['input' + str(ivar)])\n",
    "\n",
    "\n",
    "    global sys_information\n",
    "    sys_information = ['objective','probability','weighting','iteration']\n",
    "    #sys_information = ['objective','probability','weighting']\n",
    "    pd_header.extend(sys_information)\n",
    "# ===============================================================================\n",
    "\n",
    "    grid_type = []\n",
    "    grid_bias_ = []\n",
    "    search_space = []\n",
    "    # -------------- create mesh\n",
    "    for ivar in range(no_variables):\n",
    "        grid_type.append(searchMesh[ivar][0])\n",
    "\n",
    "\n",
    "        # only for 'polynomial' method\n",
    "        if(grid_type[-1] == 'polynomial'):\n",
    "            grid_bias_.append(searchMesh[ivar][1]) # [0.~-1., order]\n",
    "\n",
    "            # define search space\n",
    "            search_space.append(searchMesh[ivar][2])\n",
    "\n",
    "        else:\n",
    "            # define search space\n",
    "            search_space.append(searchMesh[ivar][1])\n",
    "\n",
    "\n",
    "\n",
    "    search_space = np.array(search_space)\n",
    "\n",
    "    if ('log' in grid_type) & (np.any(search_space[:,0] == 0.) ):\n",
    "        sys.exit(\"illegal space variable for for 'log' method\")\n",
    "\n",
    "# ===============================================================================\n",
    "\n",
    "    optimization_method = optimization_method.lower()\n",
    "\n",
    "\n",
    "    try:\n",
    "        ind_ = optimization_method.index('-')\n",
    "    except:\n",
    "        ind_ = -1\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "    global hybrid,optimizer,search_based \n",
    "    \n",
    "    hybrid = 0\n",
    "    optimizer = ''\n",
    "    search_based = ''\n",
    "\n",
    "    if(ind_ == -1):\n",
    "        if(optimization_method == 'hybrid_1'):\n",
    "            hybrid = 1\n",
    "            optimizer = 'geneticalgorithm'\n",
    "            search_based = 'global'\n",
    "\n",
    "        elif(optimization_method == 'hybrid_2'):\n",
    "            hybrid = 2\n",
    "            optimizer = 'random'\n",
    "            search_based = 'whack-a-mole'\n",
    "\n",
    "        elif(optimization_method == 'hybrid_3'):\n",
    "            hybrid = 3\n",
    "            optimizer = 'geneticalgorithm'\n",
    "            search_based = 'family'\n",
    "\n",
    "        elif(optimization_method == 'random'):\n",
    "            optimizer = optimization_method\n",
    "\n",
    "        else:\n",
    "            sys.exit(\"illegal variable optimization_method\")\n",
    "\n",
    "    else:\n",
    "        #print(optimization_method[:ind_])\n",
    "        if(optimization_method[:ind_] == 'rf'):\n",
    "            optimizer = 'randomforest'\n",
    "\n",
    "            if(optimization_method[ind_+1:] == 'wam'):\n",
    "                search_based = 'whack-a-mole'\n",
    "            elif(optimization_method[ind_+1:] == 'mc'):\n",
    "                search_based = 'monte-carlo'\n",
    "\n",
    "        elif(optimization_method[:ind_] == 'ga'):\n",
    "            optimizer = 'geneticalgorithm'\n",
    "            search_based = optimization_method[ind_+1:]\n",
    "\n",
    "\n",
    "    # -------------- parameters for genetic algorithm\n",
    "    global GA_no_parents,mutation_rate,GA_convergence\n",
    "    GA_no_parents = 2\n",
    "    mutation_rate = 0.3\n",
    "    GA_convergence = 0.9\n",
    "\n",
    "    if (optimizer == 'geneticalgorithm') & (no_selections == 2):\n",
    "        sys.exit(\"illegal number selection for each iteration for for genetic algorithm\")\n",
    "    # --------------\n",
    "\n",
    "    # -------------- parameters for randomforest\n",
    "    RF_depth = no_selections*noIteration\n",
    "    RF_estimator = 100\n",
    "    # --------------\n",
    "\n",
    "    # ======= \n",
    "\n",
    "    global no_gridpoints,var_space\n",
    "    no_gridpoints = []\n",
    "    var_space = []\n",
    "    for ivar in range(no_variables):\n",
    "\n",
    "        no_gridpoints.append(int(np.trunc((search_space[ivar,1]-search_space[ivar,0])/search_space[ivar,2])) + 1)\n",
    "\n",
    "        if grid_type[ivar].lower() == 'polynomial':\n",
    "\n",
    "\n",
    "            grid_bias = grid_bias_[ivar][0]*no_gridpoints[-1]\n",
    "\n",
    "\n",
    "            mesh_step = np.linspace(0, no_gridpoints[-1], no_gridpoints[-1], endpoint=True)\n",
    "            mesh_function = np.cumsum((mesh_step-grid_bias)**grid_bias_[ivar][1])\n",
    "\n",
    "            dist_ = (search_space[0,0] + (search_space[0,1]-search_space[0,0])\n",
    "                     * (mesh_function-mesh_function[0])/(mesh_function[-1]-mesh_function[0]))\n",
    "\n",
    "            var_space.append(dist_)\n",
    "\n",
    "        elif grid_type[ivar].lower() == 'linear':\n",
    "            var_space.append(np.linspace(search_space[ivar,0], search_space[ivar,1], num=no_gridpoints[-1]))\n",
    "\n",
    "        elif grid_type[ivar].lower() == 'log':\n",
    "            var_space.append(np.geomspace(search_space[ivar,0], search_space[0,1], num=no_gridpoints[-1]))\n",
    "\n",
    "        else:\n",
    "            sys.exit(\"incorrect parameter: grid_type\")\n",
    "\n",
    "\n",
    "    X = np.meshgrid(*var_space)\n",
    "\n",
    "\n",
    "    eff_ = []\n",
    "    learn_max = []\n",
    "\n",
    "\n",
    "    filename = optimization_method\n",
    "\n",
    "\n",
    "\n",
    "    # initiate the search-accumulated array for GA\n",
    "    if(optimizer=='geneticalgorithm'):\n",
    "        # -------------------------------\n",
    "        global GA_search_path,GA_search_top\n",
    "\n",
    "        GA_search_path = []\n",
    "\n",
    "        # to adjust the GA_parents\n",
    "        # records the maximum objective of each search path\n",
    "        # not the global maximum\n",
    "        GA_search_top = [0]*GA_no_parents\n",
    "        # -------------------------------\n",
    "\n",
    "    if(optimization_method == 'hybrid_2' or optimization_method == 'hybrid_3'):\n",
    "\n",
    "        global prob_model_r2\n",
    "        prob_model_r2 = 0.\n",
    "\n",
    "\n",
    "\n",
    "    opt_space = pd.DataFrame(columns=pd_header)\n",
    "\n",
    "    for ivar in range(no_variables):\n",
    "        opt_space[pd_header[ivar]] = X[ivar].flatten()\n",
    "\n",
    "\n",
    "    mesh_points, tab_columns = opt_space.shape\n",
    "\n",
    "\n",
    "    opt_space['probability'] = np.cumsum(np.ones(mesh_points))/np.cumsum(np.ones(mesh_points))[-1]\n",
    "    opt_space['weighting'] = np.ones(mesh_points)\n",
    "\n",
    "\n",
    "\n",
    "    if(readfile):\n",
    "        opt_space = pd.read_csv(readfile)\n",
    "\n",
    "        if(opt_space['probability'].isnull().values.any()):\n",
    "\n",
    "            opt_space['weighting'] = np.ones(mesh_points)\n",
    "\n",
    "            evaluated = opt_space[opt_space['objective'].notnull()].index.values\n",
    "            opt_space['weighting'].loc[evaluated] = 0.\n",
    "\n",
    "\n",
    "            prob_ = np.ones(mesh_points)\n",
    "            prob_[evaluated] = 0.\n",
    "\n",
    "\n",
    "            norm_prob_ = np.cumsum(prob_*opt_space['weighting'].as_matrix().flatten())\n",
    "            opt_space['probability'] = norm_prob_ / norm_prob_[-1]\n",
    "\n",
    "\n",
    "\n",
    "    opt_results = optimization(evaluate,optimizer,noIteration,opt_space,RF_depth,RF_estimator,no_selections,saveSpace)\n",
    "\n",
    "\n",
    "\n",
    "    if(optimization_method == 'hybrid_2' or optimization_method == 'hybrid_3'):\n",
    "        learn_max.append(learning_curve[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    opt_results['objective'] = opt_results['objective'].fillna(value=-1E10)\n",
    "    opt_res = opt_results[pd_header[:-2]].iloc[opt_results['objective'].idxmax()]  #.values\n",
    "\n",
    "\n",
    "\n",
    "    return(opt_res,learning_curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(x):\n",
    "    \n",
    "    #fitness = abs(-0.01*(-0.1*(x[0]-2.1)**3. + 0.8*(x[0]-2)**2. + 0.1*x[0] - 0.6) + 0.0005/(1. + (x[0]-2.005)) )\n",
    "    fitness = abs(-np.sin(x[0]*6) + 0.05*x[0] + 0.02*(-(x[0]+0.51)**2.+4*x[0]+50.) )\n",
    "    \n",
    "    return np.around(fitness, decimals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = run(\"\",[['linear',[0.0,10.,0.01]]],evaluate,'hybrid_2',int(10),int(200),\"save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------\n",
    "#\n",
    "# select optimizer\n",
    "# 'random','geneticalgorithm'(GA),'randomforest'(RF),\n",
    "# 'hybrid_1' - 'GA-family' + 'RF-mc'\n",
    "# 'hybrid_2' - 'random' + 'RF-wam'\n",
    "# 'hybrid_3' - 'GA-family' + 'RF-wam'\n",
    "# for GA: 'GA-family','GA-global'; \n",
    "# for RF: 'RF-wam'(whack-a-mole),'RF-mc'(monte-carlo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
